FROM ubuntu:22.04

# Dockerfile variables. 
ARG CUDA_CC="86"           
ARG CUDA_VER="12.4"  
ARG NVHPC_VER="24.5"
ARG MPI_ROOT="/opt/mpich_nvhpc_gpu_install_root"
ARG SCRATCH="/usr/local/nvhpc_gpu"
ARG APP="/app"

# Shell. 
ENV SHELL=/bin/bash
ENV BASH_ENV=~/.bashrc
SHELL ["/bin/bash", "-c"]

# Working directory, make directories, install apt basics. 
RUN mkdir -p /app \
&& mkdir -p ${MPI_ROOT} \
&& mkdir -p ${SCRATCH} \
&& mkdir -p ${SCRATCH}/bin \
&& mkdir -p ${SCRATCH}/include \
&& mkdir -p ${SCRATCH}/lib \
&& apt update \
&& apt install -y \
    gpg \
    wget \
    curl \
    build-essential \
    gfortran \
    libtool \
    libtool-bin \
    python3 \ 
    git \
    autoconf \
    vim \
    libgl1-mesa-glx \
    libglu1-mesa \
    mesa-common-dev \
    libgl1-mesa-dev \
    libglu1-mesa-dev \
    libglew-dev \
    libglfw3-dev \
    freeglut3-dev \
    libglm-dev \
    libassimp-dev \
    libsoil-dev \
    libgtk-3-dev \
    pkg-config \
&& git config --global --add safe.directory '*'  

# NVHPC.
RUN curl https://developer.download.nvidia.com/hpc-sdk/ubuntu/DEB-GPG-KEY-NVIDIA-HPC-SDK | gpg --dearmor -o /usr/share/keyrings/nvidia-hpcsdk-archive-keyring.gpg \
&& echo 'deb [signed-by=/usr/share/keyrings/nvidia-hpcsdk-archive-keyring.gpg] https://developer.download.nvidia.com/hpc-sdk/ubuntu/amd64 /' | tee /etc/apt/sources.list.d/nvhpc.list \
&& apt-get update -y \
&& apt-get install -y nvhpc-24-5 

# Start up scripts and cuda lib links. 
RUN \
# ~/.bashrc
echo -e "\n\
export CUDA_CC=${CUDA_CC} \n\
export CUDA_VER=${CUDA_VER} \n\
export NVHPC_VER=${NVHPC_VER} \n\
export PLATFORM=${PLATFORM} \n\
export MPI_ROOT=${MPI_ROOT} \n\
export SCRATCH=${SCRATCH} \n\
export APP=${APP} \n\
export NVARCH=`uname -s`_`uname -m` \n\
export NVCOMPILERS=/opt/nvidia/hpc_sdk \n\
export MANPATH=\$MANPATH:\$NVCOMPILERS/\$NVARCH/24.5/compilers/man \n\
export NVHPC_ROOT=\$NVCOMPILERS/\$NVARCH/24.5 \n\
export PREVIOUS_PATH=\$PATH \n\
export PREVIOUS_CPATH=\$CPATH \n\
export PREVIOUS_LIBRARY_PATH=\$LIBRARY_PATH \n\
export PREVIOUS_LD_LIBRARY_PATH=\$LD_LIBRARY_PATH \n\
export PATH=\$SCRATCH/bin:\$MPI_ROOT/bin:\$NVHPC_ROOT/compilers/bin:\$NVHPC_ROOT/cuda/bin:\$PREVIOUS_PATH \n\
export CPATH=\$SCRATCH/include:\$MPI_ROOT/include:\$NVHPC_ROOT/compilers/include:\$NVHPC_ROOT/cuda/include:\$NVHPC_ROOT/math_libs/include \n\
export LIBRARY_PATH=\$SCRATCH/lib:\$MPI_ROOT/lib:\$NVHPC_ROOT/compilers/lib:\$NVHPC_ROOT/cuda/lib64:\$NVHPC_ROOT/cuda/lib64/stubs:\$NVHPC_ROOT/math_libs/lib64 \n\
export LD_LIBRARY_PATH=\$SCRATCH/lib:\$MPI_ROOT/lib:\$NVHPC_ROOT/compilers/lib:\$NVHPC_ROOT/cuda/lib64:\$NVHPC_ROOT/cuda/lib64/stubs:\$NVHPC_ROOT/math_libs/lib64 \n\
" > ~/.bashrc  \
# nvhpc cuda library links.
&& source ~/.bashrc \
&& ln -sf $NVHPC_ROOT/cuda/lib64/stubs/libcuda.so $NVHPC_ROOT/cuda/lib64/libcuda.so.1 

# mpich.
RUN cd /app \
&& source ~/.bashrc \
&& git clone --recursive https://github.com/pmodels/mpich.git \
&& cd mpich \
&& ./autogen.sh \
&& CC=nvc CXX=nvc++ FC=nvfortran ./configure --prefix=$MPI_ROOT --with-cuda=$NVHPC_ROOT/cuda  \
&& make -j8 && make install \
&& cd .. \
&& rm -rf mpich* 

# scalapack.
COPY SLmake.inc_nvhpc /app/
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://github.com/Reference-ScaLAPACK/scalapack.git \
&& cd scalapack \
&& cp ../SLmake.inc* ./SLmake.inc \
&& make lib \
&& cp ./libscalapack.a $SCRATCH/lib/libscalapack.a \
&& cd .. \
&& rm -rf scalapack* SLmake.inc*

# elpa.
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://github.com/marekandreas/elpa.git \
&& cd elpa \
&& ./autogen.sh \
&& CC=mpicc CXX=mpic++ FC=mpif90 ./configure \
    --prefix=$SCRATCH \
    --enable-nvidia-gpu-kernels \
    --with-cuda-path=$NVHPC_ROOT/cuda \
    --with-NVIDIA-GPU-compute-capability=sm_$CUDA_CC  \
    LDFLAGS="-L$SCRATCH/lib -L$NVHPC_ROOT/compilers/lib" \
    LIBS="$SCRATCH/lib/libscalapack.a $NVHPC_ROOT/compilers/lib/liblapack.a $NVHPC_ROOT/compilers/lib/libblas.a -lstdc++ -lcudart" \
    CFLAGS="-O3 -fPIC" \
    --disable-sse \
    # --disable-sse-assembly \
    --disable-avx --disable-avx2 --disable-avx512 \
    --disable-shared \
&& make -j8 && make install \
&& ln -sf $SCRATCH/include/elpa-*/elpa $SCRATCH/include/elpa \
&& cp $SCRATCH/include/elpa-*/modules/* $SCRATCH/include/ \
&& cd .. \
&& rm -rf elpa* 

# petsc.
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://gitlab.com/petsc/petsc.git \
&& cd petsc \
&& ./configure --prefix=$SCRATCH --with-scalar-type=complex --with-hdf5-dir=/usr/local \
&& make -j8 && make install \
&& cd .. \
&& rm -rf petsc* 

# slepc.
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://gitlab.com/slepc/slepc.git \
&& cd slepc \
&& ./configure --prefix=$SCRATCH \
&& make SLEPC_DIR=/app/slepc PETSC_DIR=$SCRATCH -j8 && make SLEPC_DIR=/app/slepc PETSC_DIR=$SCRATCH install \
&& cd .. \
&& rm -rf slepc* 

# fftw.
RUN cd /app \
&& source ~/.bashrc \
&& wget -O fftw3.tar.gz https://fftw.org/fftw-3.3.10.tar.gz \
&& tar -xzvf fftw3.tar.gz && mv fftw-* fftw3 \
&& cd fftw3 \
&& autoreconf -i \
&& CC=mpicc CXX=mpic++ FC=mpif90 ./configure --prefix=$SCRATCH CFLAGS="-fPIC" FCFLAGS="-fPIC" --enable-shared --enable-openmp --enable-mpi \
&& make -j8 && make install \
&& CC=mpicc CXX=mpic++ FC=mpif90 ./configure --prefix=$SCRATCH CFLAGS="-fPIC" FCFLAGS="-fPIC" --enable-shared --enable-openmp --enable-mpi --enable-single \
&& make -j8 && make install \
&& cd .. \
&& rm -rf fftw3* 

# zlib.
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://github.com/madler/zlib.git \
&& cd zlib \
&& ./configure --prefix=$SCRATCH \
&& make -j8 && make install \
&& cd .. \
&& rm -rf zlib*

# hdf5.
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://github.com/HDFGroup/hdf5.git \
&& cd hdf5 \
&& ./autogen.sh \
&& CC=mpicc CXX=mpic++ FC=mpif90 ./configure --prefix=$SCRATCH --enable-fortran --enable-shared --enable-parallel --with-zlib=$SCRATCH \
&& make -j8 && make install \
&& cd .. \
&& rm -rf hdf5* 

# qe.
# nvhpc gpu.
COPY ./kmesh.pl ./qe_nvhpc_gpu_make.inc ./qe_nvhpc_cpu_make.inc /app/
RUN cd /app \
&& source ~/.bashrc \
&& git clone https://gitlab.com/QEF/q-e.git && mv /app/q-e /app/qe \
&& git clone https://gitlab.com/QEF/q-e.git && mv /app/q-e /app/qe-cpu \
&& cd /app/qe \
&& source ~/.bashrc && source ~/set_nvhpc_gpu.sh \
&& CC=mpicc CXX=mpic++ FC=mpif90 ./configure \
    --prefix=$SCRATCH \
    --with-hdf5=yes \
    # --with-scalapack=yes \
    --with-cuda=$NVHPC_ROOT/cuda \
    --with-cuda-cc=$CUDA_CC \ 
    --with-cuda-runtime=$CUDA_VER \
    --enable-debug \
&& cp /app/qe_nvhpc_gpu_make.inc /app/qe/make.inc \
&& make all -j8 || true && make all -j8 && make install \
&& cd .. \
# nvhpc cpu.
&& cd /app/qe-cpu \
&& CC=mpicc CXX=mpic++ FC=mpif90 ./configure \
    --prefix=$(pwd) \
    --with-hdf5=yes \
    --with-scalapack=yes \ 
    #  --enable-debug \
&& cp /app/qe_nvhpc_cpu_make.inc /app/qe-cpu/make.inc \
&& make all -j8 || true && make all -j8 && make epw -j8 \
&& cd .. \
&& mv /app/kmesh.pl $SCRATCH/bin/ \
&& rm -rf /app/qe_nvhpc_gpu_make.inc /app/qe_nvhpc_cpu_make.inc 

# bgw.
# nvhpc gpu.
COPY ./arch_nvhpc_gpu.mk ./arch_nvhpc_cpu.mk /app/
RUN cd /app \
&& source ~/.bashrc \
# Below link obtained from berkeleygw.org website. 
&& wget -O bgw.tar.gz https://app.box.com/shared/static/22edl07muvhfnd900tnctsjjftbtcqc4.gz \
&& tar -xzvf bgw.tar.gz && mv BerkeleyGW* bgw \
&& tar -xzvf bgw.tar.gz && mv BerkeleyGW* bgw-cpu \
&& cd bgw \
&& cp ../arch_nvhpc_gpu.mk ./arch.mk \
&& make all-flavors -j8 \
&& make install INSTDIR=$SCRATCH \
&& cd .. \
&& rm -rf bgw bgw.tar.gz arch_nvhpc_gpu.mk \
# nvhpc cpu.
&& cd /app/bgw-cpu \
&& cp ../arch_nvhpc_cpu.mk ./arch.mk \
&& make all-flavors -j8 \
&& cd .. \
&& rm -rf arch_nvhpc_cpu.mk 

# miniconda.
RUN cd /app \
&& source ~/.bashrc \
&& wget -O miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh \
&& chmod u+x *.sh \
&& ./miniconda.sh -b -p $HOME/miniconda \
&& $HOME/miniconda/bin/conda init \
&& rm -rf miniconda.sh 
RUN cd /app \
&& source ~/.bashrc \
&& conda config --add channels conda-forge \
&& conda config --set channel_priority strict \
&& conda install -y mamba 

# Build essentials: cmake, ninja, cython.
RUN cd /app \
&& source ~/.bashrc \
&& pip3 install cmake ninja cython 

# Parallel: numpy (prereq), mpi4py, petsc4py, slepc4py, h5py.
RUN cd /app \
&& source ~/.bashrc \
&& pip3 install numpy \
&& MPICC=mpicc CC=gcc pip3 install --no-binary=mpi4py mpi4py \
&& CC=mpicc CXX=mpic++ FC=mpif90 PETSC_DIR=$SCRATCH pip3 install --no-deps --no-build-isolation petsc4py \
&& CC=mpicc CXX=mpic++ FC=mpif90 PETSC_DIR=$SCRATCH SLEPC_DIR=$SCRATCH pip3 install --no-deps --no-build-isolation slepc4py \
&& CC=mpicc HDF5_MPI="ON" HDF5_DIR="$SCRATCH"  pip3 install --no-binary=h5py h5py 

# Serial torch, torchvision. 
RUN cd /app \
&& pip3 install torch torchvision torchaudio 

# # torch.
# # Frontera: CMAKE_C_COMPILER=mpicc CMAKE_CXX_COMPILER=mpicxx CMAKE_CXX_FLAGS="-fstack-protector" MAX_JOBS=8 USE_MPI=1 USE_CUDA=0 USE_FBGEMM=0 BUILD_TEST=OFF python3 setup.py develop
# # Perlmutter: CMAKE_C_COMPILER=mpicc CMAKE_CXX_COMPILER=mpicxx MAX_JOBS=16 USE_CUDA=1 USE_DISTRIBUTED=1 USE_MPI=1 USE_SYSTEM_NCCL=1 BUILD_TEST=0 USE_NNPACK=0 USE_QNNPACK=0 USE_PYTORCH_QNNPATCK=0 USE_XNNPACK=0 python3 setup.py develop
# RUN cd /app \
# && source ~/.bashrc \
# && git clone --recursive https://github.com/pytorch/pytorch.git 
# RUN cd /app \
# && cd pytorch \
# && pip3 install -r requirements.txt \
# && export CMAKE_PREFIX_PATH=/root/miniconda \
# && USE_CUDA=0 USE_MPI=1 MAX_JOBS=2 python3 setup.py develop  

# # torchvision. 
# # Perlmutter: CC=mpicc CXX=mpicxx MAX_JOBS=16 python3 setup.py install
# RUN cd /app \
# && source ~/.bashrc \
# && git clone https://github.com/pytorch/vision.git \
# && cd vision \
# && MAX_JOBS=2 python3 setup.py install  \
# && cd .. && rm -rf vision 

# torch_geometric.
RUN cd /app \
&& source ~/.bashrc \
&& pip3 install torch_geometric 

# pyg_lib, torch_cluster, e3nn.
RUN cd /app \
&& source ~/.bashrc \
# && pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cpu.html \
&& pip3 install torch_cluster \
&& pip3 install e3nn 

# transformers, datasets, evaluate, accelerate.
RUN cd /app \
&& source ~/.bashrc \
&& pip3 install transformers datasets accelerate evaluate 

# Tier 1 packages.
RUN cd \app \
&& source ~/.bashrc \
&& pip3 install jax scipy sympy pandas networkx lark \
# pip3 install pyqt6 vtk
&& apt install -y libgtk-4-dev \
&& pip3 install pygobject \
&& pip3 install matplotlib seaborn pyvista[all] pyvistaqt \
&& pip3 install ase pymatgen mp_api astropy dill pyyaml xmltodict jupyterlab

# Tier 2 packages.
RUN cd /app \
&& source ~/.bashrc \
&& mamba create -y -n daskmpi-env python=3.12 dask-mpi \
&& pip3 install scikit-learn joblib xgboost tensorboard torchserve torch-model-archiver \
# && mamba create -y -n spacy-env python=3.7 spacy \
# && conda activate spacy-env \
# && python3 -m spacy download en_core_web_sm \
# && conda deactivate \
&& mamba create -y -n dolfinx-env python=3.12 fenics-dolfinx \
&& pip3 install --no-deps fp-workflow xctph xctpol \
&& pip3 install --prefer-binary pyscf \
&& pip3 install pyopengl --no-build-isolation \
&& pip3 install awscli

# Add actual cuda libraries linking if needed.  
RUN echo -e "\n\
export LIBCUDA_PATH=\$(find /usr/lib/wsl -name 'libcuda.so*' | head -n 1) \n \
\n\
if [ -n \"\$LIBCUDA_PATH\" ]; then \n \
    export LIBCUDA_DIR=\$(find /usr/lib/wsl -name 'libcuda.so*' -exec dirname {} \; | head -n 1 ) \n \
    export PREVIOUS_LIBRARY_PATH=\$LIBCUDA_DIR:\$PREVIOUS_LIBRARY_PATH \n \
    export PREVIOUS_LD_LIBRARY_PATH=\$LIBCUDA_DIR:\$PREVIOUS_LD_LIBRARY_PATH \n \
    ln -sf \$LIBCUDA_PATH \$NVHPC_ROOT/cuda/lib64/stubs/libcuda.so; \n \
fi \n\
" >> ~/.bashrc